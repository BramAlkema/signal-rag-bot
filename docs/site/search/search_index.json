{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Signal RAG Bot Documentation","text":"<p>Production-ready Signal chatbot with RAG using FAISS vector store</p>"},{"location":"#overview","title":"Overview","text":"<p>Signal RAG Bot is a secure, production-grade chatbot that integrates with Signal Messenger to provide intelligent Q&amp;A capabilities using Retrieval-Augmented Generation (RAG) over a custom knowledge base. Built with security, reliability, and deployability as core principles.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udd12 Secure by Design: Passphrase activation, rate limiting, input validation</li> <li>\ud83e\udd16 Intelligent RAG: FAISS vector search with OpenAI embeddings</li> <li>\ud83d\udcf1 Signal Integration: Linked device mode (no separate phone number needed)</li> <li>\ud83d\udc33 Production Ready: Docker deployment with health checks and monitoring</li> <li>\ud83d\udee1\ufe0f Enterprise Security: Comprehensive security controls and audit logging</li> <li>\ud83d\udcca Observable: Structured logging, metrics, and alerting</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li> <p> Getting Started</p> <p>New to Signal RAG Bot? Start here for installation and setup.</p> <p> Quick Start</p> </li> <li> <p> Deployment</p> <p>Deploy with Docker, Docker Compose, or to the cloud.</p> <p> Docker Guide</p> </li> <li> <p> Security</p> <p>Learn about security architecture and best practices.</p> <p> Security Overview</p> </li> <li> <p> API Reference</p> <p>Detailed API documentation for developers.</p> <p> API Docs</p> </li> </ul>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TB\n    A[Signal Users] --&gt; B[Signal Service E2EE]\n    B --&gt; C[signal-cli Linked Device]\n    C --&gt; D[Signal Bot Process]\n    D --&gt; E[Auth Manager]\n    D --&gt; F[Input Validation]\n    E --&gt; G[RAG Engine]\n    F --&gt; G\n    G --&gt; H[FAISS Vector Store]\n    G --&gt; I[OpenAI API]\n\n    style A fill:#e1f5ff\n    style D fill:#fff3e0\n    style G fill:#f3e5f5\n    style H fill:#e8f5e9\n    style I fill:#fce4ec\n</code></pre>"},{"location":"#system-requirements","title":"System Requirements","text":"Component Minimum Recommended OS Linux, macOS Ubuntu 20.04+, macOS 12+ Python 3.11+ 3.11+ RAM 2GB 4GB Disk 2GB 5GB Java OpenJDK 17+ OpenJDK 17+"},{"location":"#use-cases","title":"Use Cases","text":""},{"location":"#customer-support","title":"Customer Support","text":"<p>Provide 24/7 automated support to customers via Signal with knowledge base backed by your documentation.</p>"},{"location":"#internal-knowledge-base","title":"Internal Knowledge Base","text":"<p>Give employees instant access to company policies, procedures, and documentation through Signal.</p>"},{"location":"#community-qa","title":"Community Q&amp;A","text":"<p>Build a community bot that answers questions based on curated content and documentation.</p>"},{"location":"#research-assistant","title":"Research Assistant","text":"<p>Create a research assistant that can answer questions from academic papers or research documents.</p>"},{"location":"#security-highlights","title":"Security Highlights","text":"<ul> <li>Passphrase Activation: Users must provide exact passphrase before accessing the bot</li> <li>Rate Limiting: 10 messages/minute, 100 messages/hour per user</li> <li>Input Validation: Comprehensive sanitization and injection prevention</li> <li>Secrets Management: Docker secrets and environment variable support</li> <li>Audit Logging: Privacy-preserving audit trail with hashed user IDs</li> <li>Threat Detection: Suspicious pattern detection and anomaly monitoring</li> </ul>"},{"location":"#performance-characteristics","title":"Performance Characteristics","text":"<ul> <li>Response Time: p95 &lt; 5 seconds</li> <li>Search Latency: p95 &lt; 100ms</li> <li>Concurrent Users: 100+</li> <li>Uptime Target: 99%+</li> <li>Memory Usage: &lt; 2GB peak</li> </ul>"},{"location":"#whats-next","title":"What's Next?","text":"<p>New Users</p> <p>Follow our Quick Start Guide to get your bot running in 15 minutes.</p> <p>Deploying to Production</p> <p>Check out the Docker Deployment Guide for production-ready deployment.</p> <p>Security First</p> <p>Review the Security Overview before deploying to production.</p>"},{"location":"#project-information","title":"Project Information","text":"<ul> <li>License: MIT</li> <li>Repository: GitHub</li> <li>Version: 1.0.0</li> <li>Status: Production-Ready Candidate</li> </ul> <p>Built with security, reliability, and developer experience in mind.</p>"},{"location":"api/custom-rag/","title":"Custom RAG API Reference","text":"<p>Auto-generated API documentation for the CustomRAG class.</p>"},{"location":"api/custom-rag/#overview","title":"Overview","text":"<p>The <code>CustomRAG</code> class implements the core Retrieval-Augmented Generation functionality using FAISS vector store and OpenAI embeddings.</p> <p>Key Features: - PDF text extraction with metadata - Intelligent text chunking with overlap - OpenAI embeddings (text-embedding-3-small, 1536 dimensions) - FAISS vector similarity search - Context-aware response generation</p>"},{"location":"api/custom-rag/#quick-example","title":"Quick Example","text":"<pre><code>from custom_rag import CustomRAG\n\n# Initialize RAG\nrag = CustomRAG(bucket_dir=\"output_v3\")\n\n# Build index from PDFs\nrag.build_index()\n\n# Query the knowledge base\nresponse = rag.query(\"What is the main topic?\", k=3)\nprint(response)\n</code></pre>"},{"location":"api/custom-rag/#class-reference","title":"Class Reference","text":""},{"location":"api/custom-rag/#custom_rag.CustomRAG","title":"CustomRAG","text":"Source code in <code>RAG/custom_rag.py</code> <pre><code>class CustomRAG:\n    def __init__(self, bucket_dir: str = \"output_v3\"):\n        self.bucket_dir = Path(bucket_dir)\n        self.chunks = []\n        self.embeddings = None\n        self.index = None\n        self.metadata_file = \"rag_index.pkl\"\n\n    def chunk_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -&gt; List[str]:\n        \"\"\"Split text into overlapping chunks\"\"\"\n        chunks = []\n        start = 0\n        text_len = len(text)\n\n        while start &lt; text_len:\n            end = start + chunk_size\n            chunk = text[start:end]\n\n            # Try to break at sentence boundary\n            if end &lt; text_len:\n                last_period = chunk.rfind('.')\n                last_newline = chunk.rfind('\\n')\n                break_point = max(last_period, last_newline)\n                if break_point &gt; chunk_size * 0.5:  # Only if we're past halfway\n                    chunk = chunk[:break_point + 1]\n                    end = start + break_point + 1\n\n            chunks.append(chunk.strip())\n            start = end - overlap\n\n        return chunks\n\n    def load_and_chunk_buckets(self):\n        \"\"\"Load all bucket files and create chunks\"\"\"\n        print(\"\ud83d\udcda Loading bucket files...\")\n\n        for bucket_file in sorted(self.bucket_dir.glob(\"bucket_*.md\")):\n            print(f\"  Processing: {bucket_file.name}\")\n\n            with open(bucket_file, 'r') as f:\n                content = f.read()\n\n            # Extract category from filename\n            category = bucket_file.stem.replace('bucket_', '').replace('_', ' ').title()\n\n            # Create chunks with metadata\n            text_chunks = self.chunk_text(content)\n\n            for i, chunk in enumerate(text_chunks):\n                self.chunks.append({\n                    'text': chunk,\n                    'source': bucket_file.name,\n                    'category': category,\n                    'chunk_id': i\n                })\n\n        print(f\"\u2705 Created {len(self.chunks)} chunks from {len(list(self.bucket_dir.glob('bucket_*.md')))} buckets\")\n\n    def create_embeddings(self):\n        \"\"\"Create embeddings for all chunks\"\"\"\n        print(\"\\n\ud83d\udd22 Creating embeddings...\")\n\n        texts = [chunk['text'] for chunk in self.chunks]\n\n        # Batch embeddings (max 2048 per request)\n        batch_size = 100\n        all_embeddings = []\n\n        for i in range(0, len(texts), batch_size):\n            batch = texts[i:i + batch_size]\n            print(f\"  Embedding batch {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1}...\")\n\n            response = client.embeddings.create(\n                model=\"text-embedding-3-small\",\n                input=batch\n            )\n\n            batch_embeddings = [item.embedding for item in response.data]\n            all_embeddings.extend(batch_embeddings)\n\n        self.embeddings = np.array(all_embeddings).astype('float32')\n        print(f\"\u2705 Created {len(all_embeddings)} embeddings\")\n\n    def build_index(self):\n        \"\"\"Build FAISS index\"\"\"\n        print(\"\\n\ud83d\udd0d Building FAISS index...\")\n\n        dimension = self.embeddings.shape[1]\n\n        # Use IndexFlatL2 for exact search (good for &lt; 1M vectors)\n        self.index = faiss.IndexFlatL2(dimension)\n        self.index.add(self.embeddings)\n\n        print(f\"\u2705 Index built with {self.index.ntotal} vectors\")\n\n    def save_index(self):\n        \"\"\"Save index and metadata\"\"\"\n        print(\"\\n\ud83d\udcbe Saving index...\")\n\n        # Save FAISS index\n        faiss.write_index(self.index, \"rag_faiss.index\")\n\n        # Save chunks metadata\n        with open(self.metadata_file, 'wb') as f:\n            pickle.dump(self.chunks, f)\n\n        print(\"\u2705 Saved: rag_faiss.index, rag_index.pkl\")\n\n    def load_index(self):\n        \"\"\"Load pre-built index\"\"\"\n        print(\"\ud83d\udcc2 Loading index...\")\n\n        if not Path(\"rag_faiss.index\").exists():\n            raise FileNotFoundError(\"Index not found. Run build_index() first.\")\n\n        self.index = faiss.read_index(\"rag_faiss.index\")\n\n        with open(self.metadata_file, 'rb') as f:\n            self.chunks = pickle.load(f)\n\n        print(f\"\u2705 Loaded index with {self.index.ntotal} vectors\")\n\n    def search(self, query: str, k: int = 5) -&gt; List[Dict]:\n        \"\"\"Search for relevant chunks\"\"\"\n        # Embed query\n        response = client.embeddings.create(\n            model=\"text-embedding-3-small\",\n            input=[query]\n        )\n        query_embedding = np.array([response.data[0].embedding]).astype('float32')\n\n        # Search\n        distances, indices = self.index.search(query_embedding, k)\n\n        # Return results with metadata\n        results = []\n        for i, idx in enumerate(indices[0]):\n            results.append({\n                **self.chunks[idx],\n                'distance': float(distances[0][i])\n            })\n\n        return results\n\n    def query(self, question: str, k: int = 3) -&gt; str:\n        \"\"\"Query the RAG system and get an answer\"\"\"\n        # Get relevant chunks\n        results = self.search(question, k=k)\n\n        # Build context\n        context_parts = []\n        for i, result in enumerate(results, 1):\n            context_parts.append(f\"[Source {i}: {result['source']}, {result['category']}]\\n{result['text']}\\n\")\n\n        context = \"\\n---\\n\".join(context_parts)\n\n        # Create prompt\n        prompt = f\"\"\"You are a knowledgeable assistant specializing in Dutch defense industry, policy, and procurement.\n\nUse the following context to answer the question. Always cite your sources using the [Source X] references.\n\nContext:\n{context}\n\nQuestion: {question}\n\nAnswer:\"\"\"\n\n        # Get response\n        response = client.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on provided context. Always cite your sources.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            temperature=0.7\n        )\n\n        return response.choices[0].message.content\n</code></pre>"},{"location":"api/custom-rag/#custom_rag.CustomRAG.__init__","title":"__init__","text":"<pre><code>__init__(bucket_dir: str = 'output_v3')\n</code></pre> Source code in <code>RAG/custom_rag.py</code> <pre><code>def __init__(self, bucket_dir: str = \"output_v3\"):\n    self.bucket_dir = Path(bucket_dir)\n    self.chunks = []\n    self.embeddings = None\n    self.index = None\n    self.metadata_file = \"rag_index.pkl\"\n</code></pre>"},{"location":"api/custom-rag/#custom_rag.CustomRAG.chunk_text","title":"chunk_text","text":"<pre><code>chunk_text(text: str, chunk_size: int = 1000, overlap: int = 200) -&gt; List[str]\n</code></pre> <p>Split text into overlapping chunks</p> Source code in <code>RAG/custom_rag.py</code> <pre><code>def chunk_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -&gt; List[str]:\n    \"\"\"Split text into overlapping chunks\"\"\"\n    chunks = []\n    start = 0\n    text_len = len(text)\n\n    while start &lt; text_len:\n        end = start + chunk_size\n        chunk = text[start:end]\n\n        # Try to break at sentence boundary\n        if end &lt; text_len:\n            last_period = chunk.rfind('.')\n            last_newline = chunk.rfind('\\n')\n            break_point = max(last_period, last_newline)\n            if break_point &gt; chunk_size * 0.5:  # Only if we're past halfway\n                chunk = chunk[:break_point + 1]\n                end = start + break_point + 1\n\n        chunks.append(chunk.strip())\n        start = end - overlap\n\n    return chunks\n</code></pre>"},{"location":"api/custom-rag/#custom_rag.CustomRAG.create_embeddings","title":"create_embeddings","text":"<pre><code>create_embeddings()\n</code></pre> <p>Create embeddings for all chunks</p> Source code in <code>RAG/custom_rag.py</code> <pre><code>def create_embeddings(self):\n    \"\"\"Create embeddings for all chunks\"\"\"\n    print(\"\\n\ud83d\udd22 Creating embeddings...\")\n\n    texts = [chunk['text'] for chunk in self.chunks]\n\n    # Batch embeddings (max 2048 per request)\n    batch_size = 100\n    all_embeddings = []\n\n    for i in range(0, len(texts), batch_size):\n        batch = texts[i:i + batch_size]\n        print(f\"  Embedding batch {i//batch_size + 1}/{(len(texts)-1)//batch_size + 1}...\")\n\n        response = client.embeddings.create(\n            model=\"text-embedding-3-small\",\n            input=batch\n        )\n\n        batch_embeddings = [item.embedding for item in response.data]\n        all_embeddings.extend(batch_embeddings)\n\n    self.embeddings = np.array(all_embeddings).astype('float32')\n    print(f\"\u2705 Created {len(all_embeddings)} embeddings\")\n</code></pre>"},{"location":"api/custom-rag/#custom_rag.CustomRAG.build_index","title":"build_index","text":"<pre><code>build_index()\n</code></pre> <p>Build FAISS index</p> Source code in <code>RAG/custom_rag.py</code> <pre><code>def build_index(self):\n    \"\"\"Build FAISS index\"\"\"\n    print(\"\\n\ud83d\udd0d Building FAISS index...\")\n\n    dimension = self.embeddings.shape[1]\n\n    # Use IndexFlatL2 for exact search (good for &lt; 1M vectors)\n    self.index = faiss.IndexFlatL2(dimension)\n    self.index.add(self.embeddings)\n\n    print(f\"\u2705 Index built with {self.index.ntotal} vectors\")\n</code></pre>"},{"location":"api/custom-rag/#custom_rag.CustomRAG.save_index","title":"save_index","text":"<pre><code>save_index()\n</code></pre> <p>Save index and metadata</p> Source code in <code>RAG/custom_rag.py</code> <pre><code>def save_index(self):\n    \"\"\"Save index and metadata\"\"\"\n    print(\"\\n\ud83d\udcbe Saving index...\")\n\n    # Save FAISS index\n    faiss.write_index(self.index, \"rag_faiss.index\")\n\n    # Save chunks metadata\n    with open(self.metadata_file, 'wb') as f:\n        pickle.dump(self.chunks, f)\n\n    print(\"\u2705 Saved: rag_faiss.index, rag_index.pkl\")\n</code></pre>"},{"location":"api/custom-rag/#custom_rag.CustomRAG.load_index","title":"load_index","text":"<pre><code>load_index()\n</code></pre> <p>Load pre-built index</p> Source code in <code>RAG/custom_rag.py</code> <pre><code>def load_index(self):\n    \"\"\"Load pre-built index\"\"\"\n    print(\"\ud83d\udcc2 Loading index...\")\n\n    if not Path(\"rag_faiss.index\").exists():\n        raise FileNotFoundError(\"Index not found. Run build_index() first.\")\n\n    self.index = faiss.read_index(\"rag_faiss.index\")\n\n    with open(self.metadata_file, 'rb') as f:\n        self.chunks = pickle.load(f)\n\n    print(f\"\u2705 Loaded index with {self.index.ntotal} vectors\")\n</code></pre>"},{"location":"api/custom-rag/#custom_rag.CustomRAG.search","title":"search","text":"<pre><code>search(query: str, k: int = 5) -&gt; List[Dict]\n</code></pre> <p>Search for relevant chunks</p> Source code in <code>RAG/custom_rag.py</code> <pre><code>def search(self, query: str, k: int = 5) -&gt; List[Dict]:\n    \"\"\"Search for relevant chunks\"\"\"\n    # Embed query\n    response = client.embeddings.create(\n        model=\"text-embedding-3-small\",\n        input=[query]\n    )\n    query_embedding = np.array([response.data[0].embedding]).astype('float32')\n\n    # Search\n    distances, indices = self.index.search(query_embedding, k)\n\n    # Return results with metadata\n    results = []\n    for i, idx in enumerate(indices[0]):\n        results.append({\n            **self.chunks[idx],\n            'distance': float(distances[0][i])\n        })\n\n    return results\n</code></pre>"},{"location":"api/custom-rag/#custom_rag.CustomRAG.query","title":"query","text":"<pre><code>query(question: str, k: int = 3) -&gt; str\n</code></pre> <p>Query the RAG system and get an answer</p> Source code in <code>RAG/custom_rag.py</code> <pre><code>    def query(self, question: str, k: int = 3) -&gt; str:\n        \"\"\"Query the RAG system and get an answer\"\"\"\n        # Get relevant chunks\n        results = self.search(question, k=k)\n\n        # Build context\n        context_parts = []\n        for i, result in enumerate(results, 1):\n            context_parts.append(f\"[Source {i}: {result['source']}, {result['category']}]\\n{result['text']}\\n\")\n\n        context = \"\\n---\\n\".join(context_parts)\n\n        # Create prompt\n        prompt = f\"\"\"You are a knowledgeable assistant specializing in Dutch defense industry, policy, and procurement.\n\nUse the following context to answer the question. Always cite your sources using the [Source X] references.\n\nContext:\n{context}\n\nQuestion: {question}\n\nAnswer:\"\"\"\n\n        # Get response\n        response = client.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on provided context. Always cite your sources.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            temperature=0.7\n        )\n\n        return response.choices[0].message.content\n</code></pre>"},{"location":"api/custom-rag/#usage-examples","title":"Usage Examples","text":""},{"location":"api/custom-rag/#building-an-index","title":"Building an Index","text":"<pre><code>from custom_rag import CustomRAG\n\n# Initialize with custom bucket directory\nrag = CustomRAG(bucket_dir=\"my_documents\")\n\n# Build index from PDFs in bucket_dir\nrag.build_index()\n\n# Save index to disk\nrag.save_index(\"my_index.faiss\", \"my_index.pkl\")\n</code></pre> <p>Output: <pre><code>Processing PDFs...\n\u2713 Loaded 5 PDFs\n\u2713 Extracted 250 text chunks\n\u2713 Created embeddings (1536 dimensions)\n\u2713 Built FAISS index\n\u2713 Saved index successfully\n</code></pre></p>"},{"location":"api/custom-rag/#loading-an-existing-index","title":"Loading an Existing Index","text":"<pre><code>from custom_rag import CustomRAG\n\nrag = CustomRAG()\nrag.load_index(\"my_index.faiss\", \"my_index.pkl\")\n\nprint(f\"Loaded index with {len(rag.chunks)} chunks\")\n</code></pre>"},{"location":"api/custom-rag/#searching-the-knowledge-base","title":"Searching the Knowledge Base","text":"<pre><code># Search for relevant chunks\nresults = rag.search(\"authentication methods\", k=5)\n\nfor result in results:\n    print(f\"Score: {result['score']:.3f}\")\n    print(f\"Source: {result['metadata']['filename']}\")\n    print(f\"Text: {result['text'][:200]}...\")\n    print()\n</code></pre> <p>Example Output: <pre><code>Score: 0.892\nSource: security_guide.pdf, page 12\nText: Authentication methods include OAuth2, JWT tokens...\n\nScore: 0.856\nSource: api_docs.pdf, page 45\nText: The authentication flow begins with...\n</code></pre></p>"},{"location":"api/custom-rag/#querying-with-context","title":"Querying with Context","text":"<pre><code># Query with automatic context retrieval\nresponse = rag.query(\n    question=\"How do I implement OAuth2?\",\n    k=3  # Retrieve top 3 relevant chunks\n)\n\nprint(response)\n</code></pre> <p>Example Output: <pre><code>To implement OAuth2, you need to:\n\n1. Register your application to get client credentials\n2. Implement the authorization code flow\n3. Exchange authorization code for access token\n\n[Source: security_guide.pdf, page 12]\n[Source: api_docs.pdf, page 45]\n</code></pre></p>"},{"location":"api/custom-rag/#configuration","title":"Configuration","text":""},{"location":"api/custom-rag/#initialization-parameters","title":"Initialization Parameters","text":"<pre><code>CustomRAG(\n    bucket_dir: str = \"output_v3\",  # Directory containing PDFs\n    model: str = \"text-embedding-3-small\",  # OpenAI embedding model\n    chunk_size: int = 1000,  # Characters per chunk\n    chunk_overlap: int = 200,  # Overlap between chunks\n)\n</code></pre>"},{"location":"api/custom-rag/#environment-variables","title":"Environment Variables","text":"<p>The CustomRAG class uses these environment variables:</p> Variable Required Default Description <code>OPENAI_API_KEY</code> Yes - OpenAI API key <code>CHUNK_SIZE</code> No 1000 Text chunk size <code>CHUNK_OVERLAP</code> No 200 Chunk overlap size <code>SEARCH_K</code> No 3 Number of chunks to retrieve"},{"location":"api/custom-rag/#advanced-usage","title":"Advanced Usage","text":""},{"location":"api/custom-rag/#custom-chunking-strategy","title":"Custom Chunking Strategy","text":"<pre><code># Custom chunk size and overlap\nrag = CustomRAG()\nrag.chunk_size = 500  # Smaller chunks\nrag.chunk_overlap = 100  # Less overlap\n\ntext = \"Long document text...\"\nchunks = rag.chunk_text(text, chunk_size=500, overlap=100)\n</code></pre>"},{"location":"api/custom-rag/#batch-embedding-generation","title":"Batch Embedding Generation","text":"<pre><code># Generate embeddings for large datasets\nrag = CustomRAG()\n\n# Embeddings are generated in batches of 100\nrag.chunks = [{'text': f'Chunk {i}', ...} for i in range(1000)]\nrag.create_embeddings()  # Automatically batches requests\n\nprint(f\"Generated {rag.embeddings.shape[0]} embeddings\")\n</code></pre>"},{"location":"api/custom-rag/#faiss-index-configuration","title":"FAISS Index Configuration","text":"<pre><code>import faiss\nimport numpy as np\n\n# Create custom FAISS index\ndimension = 1536\nindex = faiss.IndexFlatL2(dimension)  # L2 distance\n\n# Add vectors\nvectors = np.random.rand(100, dimension).astype('float32')\nindex.add(vectors)\n\n# Use with CustomRAG\nrag = CustomRAG()\nrag.index = index\nrag.embeddings = vectors\n</code></pre>"},{"location":"api/custom-rag/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/custom-rag/#index-size","title":"Index Size","text":"<ul> <li>Small (&lt; 100 chunks): &lt; 1MB, &lt; 10ms search</li> <li>Medium (100-1000 chunks): ~10MB, ~50ms search</li> <li>Large (1000-10000 chunks): ~100MB, ~100ms search</li> <li>Very Large (&gt; 10000 chunks): &gt; 1GB, &gt; 500ms search</li> </ul>"},{"location":"api/custom-rag/#memory-usage","title":"Memory Usage","text":"<p>Approximate memory requirements:</p> <pre><code>chunks = 1000\ndimension = 1536\nembedding_size = chunks * dimension * 4  # float32 = 4 bytes\n# = 1000 * 1536 * 4 = 6.1 MB\n\n# Plus FAISS index overhead (~2x)\ntotal_memory = embedding_size * 2  # ~12 MB\n</code></pre>"},{"location":"api/custom-rag/#optimization-tips","title":"Optimization Tips","text":"<ol> <li>Reduce Chunk Size: Smaller chunks = faster search, less context</li> <li>Limit Search K: Return fewer results for faster queries</li> <li>Use FAISS GPU: For very large indexes (&gt; 100K chunks)</li> <li>Batch Embeddings: Process in batches of 100 for better throughput</li> </ol>"},{"location":"api/custom-rag/#error-handling","title":"Error Handling","text":""},{"location":"api/custom-rag/#common-errors","title":"Common Errors","text":"<p>Missing API Key: <pre><code>try:\n    rag = CustomRAG()\n    rag.create_embeddings()\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n    # Error: OPENAI_API_KEY not set\n</code></pre></p> <p>Empty Index: <pre><code>try:\n    rag = CustomRAG()\n    rag.search(\"query\")\nexcept RuntimeError as e:\n    print(f\"Error: {e}\")\n    # Error: Index not built. Call build_index() first.\n</code></pre></p> <p>Invalid PDF: <pre><code>try:\n    rag = CustomRAG()\n    rag.extract_text_from_pdf(\"corrupted.pdf\")\nexcept Exception as e:\n    print(f\"Failed to extract: {e}\")\n</code></pre></p>"},{"location":"api/custom-rag/#testing","title":"Testing","text":""},{"location":"api/custom-rag/#unit-tests","title":"Unit Tests","text":"<p>Run the CustomRAG test suite:</p> <pre><code>pytest tests/test_custom_rag.py -v\n</code></pre> <p>Coverage: - Text extraction: 8 tests - Chunking: 6 tests - Embeddings: 5 tests - Search: 6 tests - Overall coverage: 90%</p>"},{"location":"api/custom-rag/#integration-tests","title":"Integration Tests","text":"<pre><code># Test end-to-end RAG pipeline\ndef test_rag_pipeline():\n    rag = CustomRAG(bucket_dir=\"test_data\")\n    rag.build_index()\n\n    response = rag.query(\"test question\")\n    assert len(response) &gt; 0\n    assert \"Source:\" in response\n</code></pre>"},{"location":"api/custom-rag/#migration-guide","title":"Migration Guide","text":""},{"location":"api/custom-rag/#from-openai-assistant-api","title":"From OpenAI Assistant API","text":"<p>If migrating from OpenAI Assistant API:</p> <pre><code># Before (OpenAI Assistant)\nassistant = client.beta.assistants.create(\n    model=\"gpt-4\",\n    tools=[{\"type\": \"file_search\"}]\n)\nresponse = client.beta.threads.messages.create(\n    thread_id=thread.id,\n    role=\"user\",\n    content=\"Question\"\n)\n\n# After (CustomRAG)\nrag = CustomRAG()\nrag.build_index()\nresponse = rag.query(\"Question\")\n</code></pre> <p>Benefits: - \u2705 Lower cost (no assistant API fees) - \u2705 Faster responses (local FAISS search) - \u2705 Full control over chunking and embedding - \u2705 No file upload limits</p>"},{"location":"api/custom-rag/#next-steps","title":"Next Steps","text":"<ul> <li>\ud83d\udcd6 Security API - Security controls reference</li> <li>\ud83d\udd27 Error Handling API - Error handling utilities</li> <li>\ud83d\udcca Monitoring API - Metrics and logging</li> </ul>"},{"location":"api/custom-rag/#source-code","title":"Source Code","text":"<p>View source on GitHub</p>"},{"location":"deployment/docker/","title":"Docker Deployment Guide","text":"<p>Deploy Signal RAG Bot using Docker for production environments.</p>"},{"location":"deployment/docker/#overview","title":"Overview","text":"<p>The Docker deployment provides:</p> <ul> <li>\u2705 Isolated Environment: No dependency conflicts</li> <li>\u2705 Reproducible Builds: Same environment everywhere</li> <li>\u2705 Easy Updates: Pull new images and restart</li> <li>\u2705 Health Monitoring: Built-in health checks</li> <li>\u2705 Resource Limits: Controlled CPU and memory usage</li> <li>\u2705 Persistent Data: Volumes for Signal data and RAG index</li> </ul>"},{"location":"deployment/docker/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph Docker Host\n        A[Docker Engine]\n        subgraph signal-rag-bot Container\n            B[Entrypoint Script]\n            C[Signal Bot Process]\n            D[Health Check Script]\n        end\n        subgraph Volumes\n            E[signal-data]\n            F[rag-index]\n            G[logs]\n        end\n        C --&gt; E\n        C --&gt; F\n        C --&gt; G\n    end\n\n    style A fill:#2196F3\n    style C fill:#4CAF50\n    style E fill:#FFC107\n    style F fill:#FFC107\n    style G fill:#FFC107\n</code></pre>"},{"location":"deployment/docker/#docker-image-details","title":"Docker Image Details","text":""},{"location":"deployment/docker/#multi-stage-build","title":"Multi-Stage Build","text":"<p>The Dockerfile uses a two-stage build for optimization:</p> <p>Stage 1: Builder - Base: <code>python:3.11-slim</code> - Installs: gcc, g++, make, wget, git - Downloads: signal-cli binary - Creates: Python virtual environment with dependencies - Size: ~800MB (discarded after build)</p> <p>Stage 2: Runtime - Base: <code>python:3.11-slim</code> - Installs: OpenJDK 17 JRE (for signal-cli), curl, ca-certificates - Copies: Virtual environment and signal-cli from builder - Final size: &lt; 500MB</p>"},{"location":"deployment/docker/#image-contents","title":"Image Contents","text":"<pre><code>/app/\n\u251c\u2500\u2500 custom_rag.py           # RAG implementation\n\u251c\u2500\u2500 security.py             # Security controls\n\u251c\u2500\u2500 error_handling.py       # Error handling\n\u251c\u2500\u2500 monitoring.py           # Monitoring and metrics\n\u251c\u2500\u2500 signal_bot_rag.py       # Main bot application\n\u251c\u2500\u2500 logs/                   # Log directory (volume)\n\u2514\u2500\u2500 index/                  # RAG index directory (volume)\n\n/opt/signal-cli/            # signal-cli installation\n/opt/venv/                  # Python virtual environment\n/usr/local/bin/\n\u251c\u2500\u2500 healthcheck             # Health check script\n\u2514\u2500\u2500 entrypoint              # Entrypoint script\n</code></pre>"},{"location":"deployment/docker/#building-the-image","title":"Building the Image","text":""},{"location":"deployment/docker/#basic-build","title":"Basic Build","text":"<pre><code>docker build -t signal-rag-bot:latest .\n</code></pre>"},{"location":"deployment/docker/#build-with-custom-tag","title":"Build with Custom Tag","text":"<pre><code>docker build -t signal-rag-bot:v1.0.0 .\n</code></pre>"},{"location":"deployment/docker/#build-with-buildkit-faster","title":"Build with BuildKit (faster)","text":"<pre><code>DOCKER_BUILDKIT=1 docker build -t signal-rag-bot:latest .\n</code></pre>"},{"location":"deployment/docker/#verify-image-size","title":"Verify Image Size","text":"<pre><code>docker images signal-rag-bot\n</code></pre> <p>Expected output: <pre><code>REPOSITORY         TAG       SIZE\nsignal-rag-bot     latest    487MB\n</code></pre></p>"},{"location":"deployment/docker/#running-the-container","title":"Running the Container","text":""},{"location":"deployment/docker/#using-docker-run","title":"Using docker run","text":"<pre><code>docker run -d \\\n  --name signal-rag-bot \\\n  --restart unless-stopped \\\n  -e OPENAI_API_KEY=\"sk-your-key\" \\\n  -e SIGNAL_PHONE_NUMBER=\"+31612345678\" \\\n  -e ACTIVATION_PASSPHRASE=\"Activate Oracle\" \\\n  -v signal-data:/root/.local/share/signal-cli \\\n  -v rag-index:/app/index \\\n  -v $(pwd)/logs:/app/logs \\\n  signal-rag-bot:latest\n</code></pre>"},{"location":"deployment/docker/#using-docker-compose-recommended","title":"Using Docker Compose (Recommended)","text":"<p>See Docker Compose Guide for full details.</p>"},{"location":"deployment/docker/#environment-variables","title":"Environment Variables","text":""},{"location":"deployment/docker/#required-variables","title":"Required Variables","text":"Variable Description Example <code>OPENAI_API_KEY</code> OpenAI API key (must start with <code>sk-</code>) <code>sk-proj-abc123...</code> <code>SIGNAL_PHONE_NUMBER</code> Phone number in E.164 format <code>+31612345678</code>"},{"location":"deployment/docker/#optional-variables","title":"Optional Variables","text":"Variable Default Description <code>ACTIVATION_PASSPHRASE</code> <code>\"Activate Oracle\"</code> Passphrase for activation <code>AUTHORIZED_USERS</code> <code>\"\"</code> Comma-separated phone numbers <code>LOG_LEVEL</code> <code>INFO</code> Logging level (DEBUG, INFO, WARNING, ERROR) <code>MAX_TOKENS</code> <code>200</code> Max response tokens <code>CHUNK_SIZE</code> <code>1000</code> Text chunk size for RAG <code>CHUNK_OVERLAP</code> <code>200</code> Chunk overlap size <code>SEARCH_K</code> <code>3</code> Number of chunks to retrieve"},{"location":"deployment/docker/#volume-management","title":"Volume Management","text":""},{"location":"deployment/docker/#persistent-volumes","title":"Persistent Volumes","text":"<p>The container uses three volumes:</p> <pre><code>volumes:\n  # Signal account data (MUST persist)\n  - signal-data:/root/.local/share/signal-cli\n\n  # RAG index files (MUST persist)\n  - rag-index:/app/index\n\n  # Application logs (optional)\n  - ./logs:/app/logs\n</code></pre>"},{"location":"deployment/docker/#backup-volumes","title":"Backup Volumes","text":"<pre><code># Backup signal-data\ndocker run --rm \\\n  -v signal-data:/data \\\n  -v $(pwd)/backups:/backup \\\n  alpine tar czf /backup/signal-data-$(date +%Y%m%d).tar.gz /data\n\n# Backup rag-index\ndocker run --rm \\\n  -v rag-index:/data \\\n  -v $(pwd)/backups:/backup \\\n  alpine tar czf /backup/rag-index-$(date +%Y%m%d).tar.gz /data\n</code></pre>"},{"location":"deployment/docker/#restore-volumes","title":"Restore Volumes","text":"<pre><code># Restore signal-data\ndocker run --rm \\\n  -v signal-data:/data \\\n  -v $(pwd)/backups:/backup \\\n  alpine tar xzf /backup/signal-data-20251005.tar.gz -C /\n\n# Restore rag-index\ndocker run --rm \\\n  -v rag-index:/data \\\n  -v $(pwd)/backups:/backup \\\n  alpine tar xzf /backup/rag-index-20251005.tar.gz -C /\n</code></pre>"},{"location":"deployment/docker/#health-checks","title":"Health Checks","text":""},{"location":"deployment/docker/#built-in-health-check","title":"Built-in Health Check","text":"<p>The Docker image includes a comprehensive health check script that validates:</p> <ul> <li>\u2705 Python process is running</li> <li>\u2705 signal-cli is accessible</li> <li>\u2705 FAISS index exists</li> <li>\u2705 Environment variables are set</li> <li>\u2705 Disk space is available (&gt; 1GB)</li> </ul>"},{"location":"deployment/docker/#health-check-configuration","title":"Health Check Configuration","text":"<pre><code>healthcheck:\n  test: [\"/usr/local/bin/healthcheck\"]\n  interval: 30s      # Check every 30 seconds\n  timeout: 10s       # Timeout after 10 seconds\n  start_period: 60s  # Grace period on startup\n  retries: 3         # Mark unhealthy after 3 failures\n</code></pre>"},{"location":"deployment/docker/#check-container-health","title":"Check Container Health","text":"<pre><code># View health status\ndocker inspect signal-rag-bot | jq '.[0].State.Health'\n\n# Watch health status\nwatch -n 5 'docker inspect signal-rag-bot | jq \".[0].State.Health.Status\"'\n</code></pre> <p>Expected output (healthy): <pre><code>{\n  \"Status\": \"healthy\",\n  \"FailingStreak\": 0,\n  \"Log\": [\n    {\n      \"Start\": \"2025-10-05T14:30:00Z\",\n      \"End\": \"2025-10-05T14:30:01Z\",\n      \"ExitCode\": 0,\n      \"Output\": \"[HEALTH] \u2713 All checks passed\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"deployment/docker/#entrypoint-script","title":"Entrypoint Script","text":"<p>The entrypoint script performs startup validation:</p>"},{"location":"deployment/docker/#validation-steps","title":"Validation Steps","text":"<ol> <li>Environment Variable Validation</li> <li>Checks <code>OPENAI_API_KEY</code> format (must start with <code>sk-</code>)</li> <li>Checks <code>SIGNAL_PHONE_NUMBER</code> format (E.164: <code>+[1-9][0-9]{7,14}</code>)</li> <li> <p>Validates required variables are set</p> </li> <li> <p>Docker Secrets Support</p> </li> <li>Checks <code>/run/secrets/openai_api_key</code></li> <li>Checks <code>/run/secrets/signal_phone_number</code></li> <li>Checks <code>/run/secrets/activation_passphrase</code></li> <li> <p>Overrides environment variables if secrets found</p> </li> <li> <p>File System Checks</p> </li> <li>Verifies write permissions on <code>/app/logs</code></li> <li> <p>Verifies write permissions on <code>/app/index</code></p> </li> <li> <p>Dependency Checks</p> </li> <li>Validates Python packages installed</li> <li>Validates signal-cli accessible</li> </ol>"},{"location":"deployment/docker/#failure-modes","title":"Failure Modes","text":"<p>If validation fails, the container exits with: - Exit code <code>1</code> - Clear error message in logs - No partial startup</p> <p>Example error: <pre><code>[ENTRYPOINT] \u2717 OPENAI_API_KEY format is invalid (should start with 'sk-')\n[ENTRYPOINT] \u2717 Environment validation FAILED\n</code></pre></p>"},{"location":"deployment/docker/#resource-limits","title":"Resource Limits","text":""},{"location":"deployment/docker/#recommended-limits","title":"Recommended Limits","text":"<pre><code>deploy:\n  resources:\n    limits:\n      cpus: '2.0'      # Max 2 CPU cores\n      memory: 2G       # Max 2GB RAM\n    reservations:\n      cpus: '0.5'      # Reserve 0.5 CPU cores\n      memory: 512M     # Reserve 512MB RAM\n</code></pre>"},{"location":"deployment/docker/#monitoring-resource-usage","title":"Monitoring Resource Usage","text":"<pre><code># Real-time resource usage\ndocker stats signal-rag-bot\n\n# Sample output\nCONTAINER         CPU %     MEM USAGE / LIMIT     MEM %\nsignal-rag-bot    5.23%     847MiB / 2GiB        41.35%\n</code></pre>"},{"location":"deployment/docker/#security-options","title":"Security Options","text":""},{"location":"deployment/docker/#security-configuration","title":"Security Configuration","text":"<pre><code>security_opt:\n  - no-new-privileges:true  # Prevent privilege escalation\n</code></pre>"},{"location":"deployment/docker/#additional-security","title":"Additional Security","text":"<pre><code># Run as non-root user (add to Dockerfile)\nRUN useradd -m -u 1000 botuser\nUSER botuser\n\n# Read-only root filesystem (add to docker-compose.yml)\nread_only: true\ntmpfs:\n  - /tmp\n  - /app/logs\n</code></pre>"},{"location":"deployment/docker/#logging","title":"Logging","text":""},{"location":"deployment/docker/#log-configuration","title":"Log Configuration","text":"<pre><code>logging:\n  driver: \"json-file\"\n  options:\n    max-size: \"10m\"      # Max 10MB per log file\n    max-file: \"5\"        # Keep 5 rotated files\n    labels: \"service=signal-rag-bot\"\n</code></pre>"},{"location":"deployment/docker/#view-logs","title":"View Logs","text":"<pre><code># Follow logs in real-time\ndocker logs -f signal-rag-bot\n\n# View last 100 lines\ndocker logs --tail 100 signal-rag-bot\n\n# View logs since 1 hour ago\ndocker logs --since 1h signal-rag-bot\n\n# View logs with timestamps\ndocker logs -t signal-rag-bot\n</code></pre>"},{"location":"deployment/docker/#export-logs","title":"Export Logs","text":"<pre><code># Export to file\ndocker logs signal-rag-bot &gt; bot-logs-$(date +%Y%m%d).log\n\n# Export JSON logs\ndocker logs signal-rag-bot 2&gt;&amp;1 | jq '.' &gt; structured-logs.json\n</code></pre>"},{"location":"deployment/docker/#updating-the-container","title":"Updating the Container","text":""},{"location":"deployment/docker/#update-process","title":"Update Process","text":"<pre><code># 1. Pull latest code\ngit pull origin main\n\n# 2. Rebuild image\ndocker-compose build\n\n# 3. Stop current container\ndocker-compose down\n\n# 4. Start with new image\ndocker-compose up -d\n\n# 5. Verify health\ndocker-compose ps\ndocker-compose logs -f\n</code></pre>"},{"location":"deployment/docker/#zero-downtime-update-advanced","title":"Zero-Downtime Update (Advanced)","text":"<pre><code># 1. Start new container with different name\ndocker-compose -p signal-rag-bot-new up -d\n\n# 2. Verify new container is healthy\ndocker inspect signal-rag-bot-new_signal-rag-bot_1 | jq '.[0].State.Health.Status'\n\n# 3. Stop old container\ndocker-compose -p signal-rag-bot down\n\n# 4. Rename new container\ndocker rename signal-rag-bot-new_signal-rag-bot_1 signal-rag-bot\n</code></pre>"},{"location":"deployment/docker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/docker/#container-wont-start","title":"Container Won't Start","text":"<p>Check entrypoint validation: <pre><code>docker logs signal-rag-bot | grep ENTRYPOINT\n</code></pre></p> <p>Common issues: - Invalid <code>OPENAI_API_KEY</code> format - Invalid phone number format - Missing environment variables</p>"},{"location":"deployment/docker/#container-is-unhealthy","title":"Container is Unhealthy","text":"<p>Check health check logs: <pre><code>docker inspect signal-rag-bot | jq '.[0].State.Health.Log[-1]'\n</code></pre></p> <p>Common issues: - FAISS index not found - signal-cli not responding - Disk space &lt; 1GB</p>"},{"location":"deployment/docker/#high-memory-usage","title":"High Memory Usage","text":"<p>Check memory stats: <pre><code>docker stats signal-rag-bot --no-stream\n</code></pre></p> <p>Solutions: - Reduce <code>SEARCH_K</code> value - Reduce <code>CHUNK_SIZE</code> - Increase memory limit in docker-compose.yml</p>"},{"location":"deployment/docker/#permission-errors","title":"Permission Errors","text":"<p>Verify volume permissions: <pre><code>docker exec signal-rag-bot ls -la /app/logs\ndocker exec signal-rag-bot ls -la /app/index\n</code></pre></p> <p>Fix permissions: <pre><code>docker exec signal-rag-bot chown -R 1000:1000 /app/logs\ndocker exec signal-rag-bot chown -R 1000:1000 /app/index\n</code></pre></p>"},{"location":"deployment/docker/#next-steps","title":"Next Steps","text":"<ul> <li>\ud83d\udcd6 Docker Compose Guide - Orchestration with Docker Compose</li> <li>\ud83d\udd10 Docker Secrets - Secure credential management</li> <li>\u2601\ufe0f Cloud Deployment - Deploy to AWS, DigitalOcean, GCP</li> <li>\ud83d\udd27 VPS Deployment - Deploy to your own VPS</li> </ul>"},{"location":"deployment/docker/#reference","title":"Reference","text":"<ul> <li>Dockerfile Source</li> <li>Health Check Script</li> <li>Entrypoint Script</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start Guide","text":"<p>Get your Signal RAG Bot running in 15 minutes.</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li> Signal account (mobile app installed)</li> <li> OpenAI API key (Get one here)</li> <li> Linux or macOS system</li> <li> Docker and Docker Compose installed</li> </ul> <p>Docker Installation</p> <p>Don't have Docker? Install it from docker.com/get-started</p>"},{"location":"getting-started/quickstart/#step-1-clone-the-repository","title":"Step 1: Clone the Repository","text":"<pre><code>git clone https://github.com/BramAlkema/signal-rag-bot.git\ncd signal-rag-bot\n</code></pre>"},{"location":"getting-started/quickstart/#step-2-configure-environment-variables","title":"Step 2: Configure Environment Variables","text":"<p>Create a <code>.env</code> file with your credentials:</p> <pre><code>cat &gt; .env &lt;&lt; EOF\nOPENAI_API_KEY=sk-your-openai-api-key-here\nSIGNAL_PHONE_NUMBER=+31612345678\nACTIVATION_PASSPHRASE=Activate Oracle\nLOG_LEVEL=INFO\nEOF\n</code></pre> <p>E.164 Format Required</p> <p>Phone number must be in E.164 format: <code>+[country_code][number]</code></p> <p>Examples: <code>+31612345678</code> (Netherlands), <code>+14155552671</code> (USA)</p> <p>Keep Your Secrets Safe</p> <p>Never commit <code>.env</code> files to git. They are already in <code>.gitignore</code>.</p>"},{"location":"getting-started/quickstart/#step-3-build-the-docker-image","title":"Step 3: Build the Docker Image","text":"<pre><code>docker-compose build\n</code></pre> <p>Expected output: <pre><code>[+] Building 45.3s (12/12) FINISHED\n =&gt; [internal] load build definition from Dockerfile\n =&gt; [internal] load .dockerignore\n =&gt; [build 1/4] RUN apt-get update &amp;&amp; apt-get install -y gcc g++ make wget\n =&gt; [build 2/4] COPY requirements.txt /tmp/\n =&gt; [build 3/4] RUN pip install --no-cache-dir -r /tmp/requirements.txt\n =&gt; [runtime 1/3] RUN apt-get update &amp;&amp; apt-get install -y openjdk-17-jre\n =&gt; exporting to image\n =&gt; =&gt; naming to docker.io/library/signal-rag-bot:latest\n</code></pre></p>"},{"location":"getting-started/quickstart/#step-4-link-signal-account","title":"Step 4: Link Signal Account","text":"<p>Start the container in interactive mode to link your Signal account:</p> <pre><code>docker-compose run --rm signal-rag-bot signal-cli link -n \"RAG-Bot\"\n</code></pre> <p>A QR code will appear in your terminal. Scan it with your Signal app:</p> <ol> <li>Open Signal on your phone</li> <li>Tap your profile \u2192 Linked Devices</li> <li>Tap + (Link New Device)</li> <li>Scan the QR code</li> </ol> <p>Linked Successfully</p> <p>You'll see a confirmation message once linking is complete.</p>"},{"location":"getting-started/quickstart/#step-5-prepare-your-knowledge-base","title":"Step 5: Prepare Your Knowledge Base","text":"<p>Build the FAISS index from your PDFs:</p> <pre><code># Place your PDFs in the input directory\nmkdir -p input\ncp /path/to/your/pdfs/*.pdf input/\n\n# Build the RAG index\ndocker-compose run --rm signal-rag-bot python custom_rag.py build\n</code></pre> <p>Expected output: <pre><code>Processing PDFs...\n\u2713 Extracted 250 chunks from 5 PDFs\n\u2713 Generated embeddings (1536 dimensions)\n\u2713 Built FAISS index (250 vectors)\n\u2713 Saved to rag_faiss.index and rag_index.pkl\n</code></pre></p> <p>First Time Setup</p> <p>Building the index takes ~2-5 minutes depending on PDF size and count.</p>"},{"location":"getting-started/quickstart/#step-6-start-the-bot","title":"Step 6: Start the Bot","text":"<pre><code>docker-compose up -d\n</code></pre> <p>Check the logs to verify it's running:</p> <pre><code>docker-compose logs -f signal-rag-bot\n</code></pre> <p>You should see: <pre><code>[ENTRYPOINT] \u2713 Loaded OPENAI_API_KEY from environment\n[ENTRYPOINT] \u2713 Loaded SIGNAL_PHONE_NUMBER from environment\n[ENTRYPOINT] \u2713 Environment validation passed\n[INFO] Signal RAG Bot starting...\n[INFO] Loaded FAISS index with 250 vectors\n[INFO] Waiting for messages...\n</code></pre></p> <p>Bot is Running!</p> <p>Your bot is now live and listening for messages.</p>"},{"location":"getting-started/quickstart/#step-7-test-the-bot","title":"Step 7: Test the Bot","text":"<p>Send a message to yourself in Signal:</p> <ol> <li>Open Signal app</li> <li>Tap Note to Self (or send to your own number)</li> <li>Send: <code>Activate Oracle</code></li> <li>Wait for activation confirmation</li> <li>Ask a question: <code>What is the main topic of the documents?</code></li> </ol> <p>Expected conversation: <pre><code>You: Activate Oracle\nBot: \u2705 Activated! You can now ask me questions.\n\nYou: What is the main topic of the documents?\nBot: Based on the provided context, the main topic covers...\n[Source: document.pdf, page 5]\n</code></pre></p>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<p>Configuration</p> <p>Learn about all configuration options in the Configuration Guide</p> <p>Production Deployment</p> <p>Ready for production? See the Docker Deployment Guide</p> <p>Security</p> <p>Review the Security Best Practices before exposing your bot</p>"},{"location":"getting-started/quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quickstart/#bot-doesnt-respond","title":"Bot doesn't respond","text":"<p>Check the logs for errors: <pre><code>docker-compose logs signal-rag-bot | grep ERROR\n</code></pre></p>"},{"location":"getting-started/quickstart/#qr-code-not-appearing","title":"QR code not appearing","text":"<p>Ensure you're running in interactive mode: <pre><code>docker-compose run --rm signal-rag-bot signal-cli link -n \"RAG-Bot\"\n</code></pre></p>"},{"location":"getting-started/quickstart/#index-build-fails","title":"Index build fails","text":"<p>Verify PDFs are valid and readable: <pre><code>ls -lh input/*.pdf\n</code></pre></p>"},{"location":"getting-started/quickstart/#cant-find-faiss-index","title":"Can't find FAISS index","text":"<p>Ensure you ran the build command and check volumes: <pre><code>docker volume ls | grep rag-index\n</code></pre></p>"},{"location":"getting-started/quickstart/#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcd6 Documentation: Browse the full docs for detailed guides</li> <li>\ud83d\udc1b Issues: Report bugs on GitHub Issues</li> <li>\ud83d\udcac Discussions: Join the community on GitHub Discussions</li> </ul> <p>Congratulations! You now have a fully functional Signal RAG Bot. \ud83c\udf89</p>"},{"location":"operations/monitoring/","title":"Monitoring Guide","text":"<p>Comprehensive monitoring and observability for Signal RAG Bot.</p>"},{"location":"operations/monitoring/#overview","title":"Overview","text":"<p>Signal RAG Bot includes built-in monitoring capabilities:</p> <ul> <li>\ud83d\udcca Structured Logging: JSON logs with privacy protection</li> <li>\ud83d\udcc8 Metrics Collection: Prometheus-compatible metrics</li> <li>\ud83d\udd14 Alerting: Critical error notifications</li> <li>\ud83c\udfe5 Health Checks: Container health validation</li> <li>\ud83d\udd0d Audit Trail: Security event logging</li> </ul>"},{"location":"operations/monitoring/#logging","title":"Logging","text":""},{"location":"operations/monitoring/#log-levels","title":"Log Levels","text":"<pre><code>import logging\n\n# Configure log level via environment variable\nLOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO')\n\nlogging.basicConfig(\n    level=getattr(logging, LOG_LEVEL),\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n</code></pre> Level Use Case Example DEBUG Development, troubleshooting Variable values, function calls INFO Normal operations Message received, query processed WARNING Recoverable issues Rate limit exceeded, retry attempt ERROR Errors requiring attention API call failed, invalid input CRITICAL Service-impacting failures API key invalid, index corrupted"},{"location":"operations/monitoring/#structured-logging","title":"Structured Logging","text":"<p>All logs are output in structured JSON format:</p> <pre><code>{\n  \"timestamp\": \"2025-10-05T14:23:45.123Z\",\n  \"level\": \"INFO\",\n  \"event\": \"message_received\",\n  \"user_id_hash\": \"a1b2c3d4\",\n  \"message_length\": 42,\n  \"activated\": true\n}\n</code></pre>"},{"location":"operations/monitoring/#log-rotation","title":"Log Rotation","text":"<p>Logs are automatically rotated to prevent disk space issues:</p> <pre><code>from logging.handlers import RotatingFileHandler\n\nhandler = RotatingFileHandler(\n    'logs/bot.log',\n    maxBytes=10 * 1024 * 1024,  # 10MB\n    backupCount=5  # Keep 5 backup files\n)\n</code></pre> <p>Configuration: - Max size: 10MB per file - Backup count: 5 files - Total disk usage: ~50MB</p>"},{"location":"operations/monitoring/#sensitive-data-redaction","title":"Sensitive Data Redaction","text":"<p>All logs automatically redact sensitive information:</p> <pre><code># monitoring.py:45\nclass AuditLogger:\n    def log_event(self, event_type: str, user_id: str, **kwargs):\n        # Hash user ID\n        user_hash = hashlib.sha256(user_id.encode()).hexdigest()[:16]\n\n        # Redact API keys\n        if 'api_key' in kwargs:\n            kwargs['api_key'] = '[REDACTED]'\n\n        # Redact phone numbers\n        if 'phone' in kwargs:\n            kwargs['phone'] = f\"+***{kwargs['phone'][-4:]}\"\n\n        self.logger.info(json.dumps({\n            'timestamp': time.time(),\n            'event': event_type,\n            'user_hash': user_hash,\n            **kwargs\n        }))\n</code></pre>"},{"location":"operations/monitoring/#viewing-logs","title":"Viewing Logs","text":"<p>Docker Compose: <pre><code># Follow logs in real-time\ndocker-compose logs -f signal-rag-bot\n\n# Last 100 lines\ndocker-compose logs --tail 100 signal-rag-bot\n\n# Logs since 1 hour ago\ndocker-compose logs --since 1h signal-rag-bot\n\n# Search logs for errors\ndocker-compose logs signal-rag-bot | grep ERROR\n</code></pre></p> <p>Log Files: <pre><code># View structured logs\ntail -f logs/bot.log | jq '.'\n\n# Filter by event type\ncat logs/bot.log | jq 'select(.event == \"message_received\")'\n\n# Count events by type\ncat logs/bot.log | jq -r '.event' | sort | uniq -c\n</code></pre></p>"},{"location":"operations/monitoring/#metrics","title":"Metrics","text":""},{"location":"operations/monitoring/#metrics-collection","title":"Metrics Collection","text":"<p>The bot collects these metrics:</p> <p>Message Metrics: <pre><code>{\n    \"messages_received_total\": 1523,      # Counter\n    \"messages_processed_total\": 1498,     # Counter\n    \"messages_failed_total\": 25,          # Counter\n    \"active_users\": 42,                   # Gauge\n}\n</code></pre></p> <p>Performance Metrics: <pre><code>{\n    \"response_time_seconds\": {            # Histogram\n        \"p50\": 2.1,\n        \"p95\": 4.8,\n        \"p99\": 6.2\n    },\n    \"rag_search_latency_seconds\": {       # Histogram\n        \"p50\": 0.05,\n        \"p95\": 0.12,\n        \"p99\": 0.18\n    }\n}\n</code></pre></p> <p>RAG Metrics: <pre><code>{\n    \"index_size_chunks\": 250,             # Gauge\n    \"index_size_bytes\": 10485760,         # Gauge\n    \"embeddings_created_total\": 250,      # Counter\n    \"searches_performed_total\": 1498,     # Counter\n}\n</code></pre></p> <p>API Metrics: <pre><code>{\n    \"openai_api_calls_total\": 1748,       # Counter\n    \"openai_api_errors_total\": 12,        # Counter\n    \"openai_tokens_used_total\": 125430,   # Counter\n}\n</code></pre></p>"},{"location":"operations/monitoring/#metrics-export","title":"Metrics Export","text":"<p>Prometheus Format: <pre><code># monitoring.py:178\nclass MetricsCollector:\n    def export_prometheus(self) -&gt; str:\n        \"\"\"Export metrics in Prometheus format\"\"\"\n        lines = []\n\n        for metric, value in self.metrics.items():\n            lines.append(f\"# HELP {metric}\")\n            lines.append(f\"# TYPE {metric} gauge\")\n            lines.append(f\"{metric} {value}\")\n\n        return \"\\n\".join(lines)\n</code></pre></p> <p>HTTP Endpoint: <pre><code>from http.server import HTTPServer, BaseHTTPRequestHandler\n\nclass MetricsHandler(BaseHTTPRequestHandler):\n    def do_GET(self):\n        if self.path == '/metrics':\n            metrics = collector.export_prometheus()\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/plain')\n            self.end_headers()\n            self.wfile.write(metrics.encode())\n\n# Start metrics server on port 9090\nserver = HTTPServer(('0.0.0.0', 9090), MetricsHandler)\nserver.serve_forever()\n</code></pre></p> <p>Access metrics: <pre><code>curl http://localhost:9090/metrics\n</code></pre></p>"},{"location":"operations/monitoring/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>Import the provided Grafana dashboard:</p> <pre><code>{\n  \"dashboard\": {\n    \"title\": \"Signal RAG Bot\",\n    \"panels\": [\n      {\n        \"title\": \"Messages per Minute\",\n        \"targets\": [{\n          \"expr\": \"rate(messages_received_total[1m])\"\n        }]\n      },\n      {\n        \"title\": \"Response Time (p95)\",\n        \"targets\": [{\n          \"expr\": \"histogram_quantile(0.95, response_time_seconds)\"\n        }]\n      },\n      {\n        \"title\": \"Error Rate\",\n        \"targets\": [{\n          \"expr\": \"rate(messages_failed_total[5m])\"\n        }]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"operations/monitoring/#alerting","title":"Alerting","text":""},{"location":"operations/monitoring/#alert-configuration","title":"Alert Configuration","text":"<p>Configure alerts for critical events:</p> <pre><code># monitoring.py:289\nclass AlertManager:\n    def __init__(self, webhook_url: str = None):\n        self.webhook_url = webhook_url\n        self.alert_history = deque(maxlen=100)\n\n    def send_alert(self, severity: str, message: str):\n        \"\"\"Send alert via webhook\"\"\"\n        alert = {\n            'timestamp': time.time(),\n            'severity': severity,\n            'message': message,\n            'service': 'signal-rag-bot'\n        }\n\n        if self.webhook_url:\n            requests.post(self.webhook_url, json=alert)\n\n        self.alert_history.append(alert)\n</code></pre>"},{"location":"operations/monitoring/#alert-rules","title":"Alert Rules","text":"<p>Critical Alerts (P0): <pre><code># API key invalid\nif 'invalid_api_key' in error_message:\n    alert_manager.send_alert('critical', 'OpenAI API key is invalid')\n\n# Signal disconnected\nif not signal_cli_responsive():\n    alert_manager.send_alert('critical', 'signal-cli not responding')\n\n# Disk space low\nif disk_space_gb &lt; 1:\n    alert_manager.send_alert('critical', f'Disk space low: {disk_space_gb}GB')\n</code></pre></p> <p>High Priority Alerts (P1): <pre><code># High error rate\nif error_rate &gt; 0.10:  # 10%\n    alert_manager.send_alert('high', f'Error rate: {error_rate:.1%}')\n\n# OpenAI quota warning\nif openai_usage_percent &gt; 80:\n    alert_manager.send_alert('high', f'OpenAI quota: {openai_usage_percent}%')\n</code></pre></p> <p>Medium Priority Alerts (P2): <pre><code># Suspicious activity\nif anomaly_detected:\n    alert_manager.send_alert('medium', f'Anomaly: {anomaly_type}')\n\n# Memory usage high\nif memory_usage_percent &gt; 80:\n    alert_manager.send_alert('medium', f'Memory usage: {memory_usage_percent}%')\n</code></pre></p>"},{"location":"operations/monitoring/#alert-channels","title":"Alert Channels","text":"<p>Slack Webhook: <pre><code># Configure Slack webhook\nSLACK_WEBHOOK_URL = os.environ.get('SLACK_WEBHOOK_URL')\n\nalert_manager = AlertManager(webhook_url=SLACK_WEBHOOK_URL)\nalert_manager.send_alert('critical', 'API key invalid')\n</code></pre></p> <p>Discord Webhook: <pre><code>DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_URL')\n\ndef send_discord_alert(message: str):\n    payload = {\n        'content': f'\ud83d\udea8 {message}',\n        'username': 'Signal RAG Bot'\n    }\n    requests.post(DISCORD_WEBHOOK_URL, json=payload)\n</code></pre></p> <p>Email (SMTP): <pre><code>import smtplib\nfrom email.mime.text import MIMEText\n\ndef send_email_alert(subject: str, message: str):\n    msg = MIMEText(message)\n    msg['Subject'] = f'[ALERT] {subject}'\n    msg['From'] = 'bot@example.com'\n    msg['To'] = 'admin@example.com'\n\n    with smtplib.SMTP('smtp.example.com') as server:\n        server.send_message(msg)\n</code></pre></p>"},{"location":"operations/monitoring/#health-checks","title":"Health Checks","text":""},{"location":"operations/monitoring/#container-health-check","title":"Container Health Check","text":"<p>The Docker image includes a comprehensive health check:</p> <pre><code>#!/bin/bash\n# docker/healthcheck.sh\n\n# Check Python process\npgrep -f \"python.*signal_bot\" || exit 1\n\n# Check signal-cli\nsignal-cli --version || exit 1\n\n# Check FAISS index\n[ -f \"/app/rag_faiss.index\" ] || exit 1\n\n# Check environment variables\n[ -n \"$OPENAI_API_KEY\" ] || exit 1\n[ -n \"$SIGNAL_PHONE_NUMBER\" ] || exit 1\n\n# Check disk space\ndf -h / | awk 'NR==2 {print $4}' | grep -q \"G$\" || exit 1\n\nexit 0\n</code></pre>"},{"location":"operations/monitoring/#health-check-status","title":"Health Check Status","text":"<pre><code># View health status\ndocker inspect signal-rag-bot | jq '.[0].State.Health'\n\n# Output:\n{\n  \"Status\": \"healthy\",\n  \"FailingStreak\": 0,\n  \"Log\": [\n    {\n      \"Start\": \"2025-10-05T14:30:00Z\",\n      \"End\": \"2025-10-05T14:30:01Z\",\n      \"ExitCode\": 0,\n      \"Output\": \"[HEALTH] \u2713 All checks passed\\n\"\n    }\n  ]\n}\n</code></pre>"},{"location":"operations/monitoring/#application-health-endpoint","title":"Application Health Endpoint","text":"<pre><code>def health_check() -&gt; dict:\n    \"\"\"Internal health check\"\"\"\n    checks = {\n        'signal_cli': check_signal_cli(),\n        'faiss_index': check_faiss_index(),\n        'openai_api': check_openai_api(),\n        'disk_space': check_disk_space(),\n        'memory': check_memory_usage()\n    }\n\n    all_healthy = all(checks.values())\n\n    return {\n        'status': 'healthy' if all_healthy else 'unhealthy',\n        'checks': checks,\n        'timestamp': time.time()\n    }\n</code></pre>"},{"location":"operations/monitoring/#audit-trail","title":"Audit Trail","text":""},{"location":"operations/monitoring/#security-event-logging","title":"Security Event Logging","text":"<pre><code># monitoring.py:45\nclass AuditLogger:\n    def log_activation_attempt(self, user_id: str, success: bool):\n        self.log_event('activation_attempt', user_id, success=success)\n\n    def log_rate_limit_exceeded(self, user_id: str, limit_type: str):\n        self.log_event('rate_limit_exceeded', user_id, limit_type=limit_type)\n\n    def log_suspicious_input(self, user_id: str, pattern: str):\n        self.log_event('suspicious_input', user_id, pattern=pattern)\n\n    def log_query(self, user_id: str, query_length: int, response_time: float):\n        self.log_event('query_processed', user_id,\n                      query_length=query_length,\n                      response_time=response_time)\n</code></pre>"},{"location":"operations/monitoring/#audit-log-format","title":"Audit Log Format","text":"<pre><code>{\n  \"timestamp\": 1696512225.123,\n  \"event\": \"activation_attempt\",\n  \"user_hash\": \"a1b2c3d4e5f6g7h8\",\n  \"success\": false,\n  \"ip_hash\": \"x1y2z3a4b5c6d7e8\"\n}\n</code></pre>"},{"location":"operations/monitoring/#compliance-reporting","title":"Compliance Reporting","text":"<pre><code># Generate compliance report\ndef generate_audit_report(start_date: str, end_date: str) -&gt; dict:\n    \"\"\"Generate audit report for compliance\"\"\"\n    events = load_audit_logs(start_date, end_date)\n\n    report = {\n        'period': f\"{start_date} to {end_date}\",\n        'total_events': len(events),\n        'events_by_type': Counter(e['event'] for e in events),\n        'unique_users': len(set(e['user_hash'] for e in events)),\n        'failed_activations': sum(1 for e in events\n                                  if e['event'] == 'activation_attempt'\n                                  and not e['success']),\n        'suspicious_activity': sum(1 for e in events\n                                   if e['event'] == 'suspicious_input')\n    }\n\n    return report\n</code></pre>"},{"location":"operations/monitoring/#monitoring-best-practices","title":"Monitoring Best Practices","text":""},{"location":"operations/monitoring/#1-set-up-alerts","title":"1. Set Up Alerts","text":"<pre><code># Configure webhook in .env\necho \"SLACK_WEBHOOK_URL=https://hooks.slack.com/...\" &gt;&gt; .env\n\n# Restart to apply\ndocker-compose restart\n</code></pre>"},{"location":"operations/monitoring/#2-monitor-disk-space","title":"2. Monitor Disk Space","text":"<pre><code># Check disk usage\ndf -h /var/lib/docker/volumes\n\n# Set up cron for cleanup\ncrontab -e\n# 0 2 * * * docker system prune -af --volumes --filter \"until=168h\"\n</code></pre>"},{"location":"operations/monitoring/#3-review-logs-daily","title":"3. Review Logs Daily","text":"<pre><code># Check for errors\ndocker-compose logs --since 24h signal-rag-bot | grep ERROR\n\n# Check for warnings\ndocker-compose logs --since 24h signal-rag-bot | grep WARNING\n</code></pre>"},{"location":"operations/monitoring/#4-track-metrics-trends","title":"4. Track Metrics Trends","text":"<pre><code># Export metrics to file\ncurl http://localhost:9090/metrics &gt; metrics-$(date +%Y%m%d).txt\n\n# Compare over time\ndiff metrics-20251001.txt metrics-20251005.txt\n</code></pre>"},{"location":"operations/monitoring/#5-test-alerts","title":"5. Test Alerts","text":"<pre><code># Trigger test alert\ndocker exec signal-rag-bot python -c \"\nfrom monitoring import AlertManager\nalert = AlertManager(webhook_url='$SLACK_WEBHOOK_URL')\nalert.send_alert('medium', 'Test alert - please ignore')\n\"\n</code></pre>"},{"location":"operations/monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/monitoring/#high-memory-usage","title":"High Memory Usage","text":"<pre><code># Check memory stats\ndocker stats signal-rag-bot --no-stream\n\n# Reduce chunk size\ndocker exec signal-rag-bot env CHUNK_SIZE=500 python signal_bot_rag.py\n</code></pre>"},{"location":"operations/monitoring/#logs-not-rotating","title":"Logs Not Rotating","text":"<pre><code># Check log rotation\nls -lh logs/\n\n# Force rotation\ndocker exec signal-rag-bot python -c \"\nimport logging.handlers\nhandler = logging.handlers.RotatingFileHandler('logs/bot.log')\nhandler.doRollover()\n\"\n</code></pre>"},{"location":"operations/monitoring/#metrics-not-updating","title":"Metrics Not Updating","text":"<pre><code># Check metrics collector\ndocker exec signal-rag-bot python -c \"\nfrom monitoring import MetricsCollector\ncollector = MetricsCollector()\nprint(collector.export_prometheus())\n\"\n</code></pre>"},{"location":"operations/monitoring/#next-steps","title":"Next Steps","text":"<ul> <li>\ud83d\udcca Health Checks - Detailed health check configuration</li> <li>\ud83d\udd27 Troubleshooting - Common issues and solutions</li> <li>\ud83d\udcbe Backup &amp; Restore - Data protection procedures</li> </ul>"},{"location":"operations/monitoring/#reference","title":"Reference","text":"<ul> <li>Monitoring Module Source</li> <li>Health Check Script</li> <li>Metrics Tests</li> </ul>"},{"location":"security/overview/","title":"Security Overview","text":"<p>Comprehensive security architecture for Signal RAG Bot.</p>"},{"location":"security/overview/#security-philosophy","title":"Security Philosophy","text":"<p>Signal RAG Bot is designed with security-first principles:</p> <ol> <li>Defense in Depth: Multiple layers of security controls</li> <li>Fail Secure: Defaults to secure state on errors</li> <li>Privacy by Design: Minimal data collection and retention</li> <li>Least Privilege: Components have minimum required permissions</li> <li>Auditability: Comprehensive logging without sensitive data exposure</li> </ol>"},{"location":"security/overview/#threat-model","title":"Threat Model","text":""},{"location":"security/overview/#assets-to-protect","title":"Assets to Protect","text":"Asset Confidentiality Integrity Availability OpenAI API Key Critical Medium High Signal Account High Critical Critical Knowledge Base High Medium Medium User Messages Medium Low Low"},{"location":"security/overview/#threat-actors","title":"Threat Actors","text":"<p>Curious User (High Likelihood, Low Impact) - Motivation: Explore capabilities - Capability: Basic Signal usage - Mitigation: Rate limiting, activation passphrase</p> <p>Malicious User (Medium Likelihood, Medium Impact) - Motivation: Abuse service, extract data - Capability: Scripting, automation - Mitigation: Input validation, anomaly detection, circuit breakers</p> <p>External Attacker (Low Likelihood, Critical Impact) - Motivation: Steal API keys, compromise system - Capability: Skilled hacker - Mitigation: Secrets management, no exposed ports, encrypted communication</p>"},{"location":"security/overview/#security-layers","title":"Security Layers","text":""},{"location":"security/overview/#layer-1-network-security","title":"Layer 1: Network Security","text":"<pre><code>graph LR\n    A[Signal Users] --&gt;|E2EE| B[Signal Service]\n    B --&gt;|E2EE| C[signal-cli]\n    C --&gt; D[Bot Process]\n    D --&gt;|HTTPS| E[OpenAI API]\n\n    style A fill:#e1f5ff\n    style E fill:#fce4ec\n</code></pre> <p>Controls: - Signal end-to-end encryption (E2EE) - HTTPS for OpenAI API calls - No inbound network ports exposed - Outbound-only connections</p>"},{"location":"security/overview/#layer-2-authentication-authorization","title":"Layer 2: Authentication &amp; Authorization","text":"<p>Passphrase Activation (<code>security.py:15</code>) <pre><code>def check_activation(user_message: str, passphrase: str) -&gt; bool:\n    \"\"\"Validate activation passphrase\"\"\"\n    return user_message.strip() == passphrase\n</code></pre></p> <p>User Whitelist (<code>security.py:45</code>) <pre><code>def is_authorized_user(sender: str, authorized_users: List[str]) -&gt; bool:\n    \"\"\"Check if user is in authorized list\"\"\"\n    if not authorized_users:\n        return True  # Allow all if list is empty\n    return sender in authorized_users\n</code></pre></p> <p>Controls: - Passphrase-based activation (default: \"Activate Oracle\") - Optional user whitelist via <code>AUTHORIZED_USERS</code> - Session-based access (in-memory, cleared on restart) - Silent rejection of unauthorized users</p>"},{"location":"security/overview/#layer-3-input-validation","title":"Layer 3: Input Validation","text":"<p>Sanitization (<code>security.py:78</code>) <pre><code>def sanitize_input(text: str, max_length: int = 2000) -&gt; str:\n    \"\"\"Sanitize user input to prevent injection attacks\"\"\"\n\n    # Length limit\n    if len(text) &gt; max_length:\n        raise ValueError(f\"Input exceeds maximum length of {max_length}\")\n\n    # Remove control characters\n    import re\n    text = re.sub(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]', '', text)\n\n    # Check for command injection patterns\n    dangerous_patterns = [';', '&amp;&amp;', '||', '`', '$(', '${', '\\n']\n    for pattern in dangerous_patterns:\n        if pattern in text:\n            raise ValueError(\"Potentially dangerous input detected\")\n\n    return text.strip()\n</code></pre></p> <p>Rate Limiting (<code>security.py:112</code>) <pre><code>class RateLimiter:\n    \"\"\"Token bucket rate limiter\"\"\"\n\n    def __init__(self, rate_per_minute: int = 10, rate_per_hour: int = 100):\n        self.rate_per_minute = rate_per_minute\n        self.rate_per_hour = rate_per_hour\n        self.user_timestamps = defaultdict(deque)\n\n    def is_allowed(self, user_id: str) -&gt; tuple[bool, str]:\n        \"\"\"Check if user is within rate limits\"\"\"\n        now = time.time()\n        timestamps = self.user_timestamps[user_id]\n\n        # Clean old timestamps\n        while timestamps and timestamps[0] &lt; now - 3600:\n            timestamps.popleft()\n\n        # Count recent requests\n        last_minute = sum(1 for ts in timestamps if ts &gt; now - 60)\n        last_hour = len(timestamps)\n\n        if last_minute &gt;= self.rate_per_minute:\n            return False, f\"Rate limit: {self.rate_per_minute} msg/min\"\n\n        if last_hour &gt;= self.rate_per_hour:\n            return False, f\"Rate limit: {self.rate_per_hour} msg/hour\"\n\n        # Record request\n        timestamps.append(now)\n        return True, \"\"\n</code></pre></p> <p>Controls: - Max message length: 2000 characters - Control character stripping - Command injection prevention - 10 messages/minute per user - 100 messages/hour per user</p>"},{"location":"security/overview/#layer-4-threat-detection","title":"Layer 4: Threat Detection","text":"<p>Suspicious Pattern Detection (<code>security.py:187</code>) <pre><code>class ThreatDetector:\n    \"\"\"Detect suspicious input patterns\"\"\"\n\n    PATTERNS = [\n        r'ignore.*previous.*instructions',\n        r'system.*prompt',\n        r'&lt;\\|.*\\|&gt;',\n        r'&lt;/context&gt;',\n        r'\\\\x[0-9a-f]{2}',  # Hex encoding\n        r'eval\\(',\n        r'exec\\(',\n    ]\n\n    def is_suspicious(self, text: str) -&gt; tuple[bool, str]:\n        \"\"\"Check for suspicious patterns\"\"\"\n        text_lower = text.lower()\n\n        for pattern in self.PATTERNS:\n            if re.search(pattern, text_lower):\n                return True, f\"Suspicious pattern: {pattern}\"\n\n        # Excessive special characters\n        special_ratio = sum(1 for c in text if not c.isalnum() and c not in ' .,!?') / max(len(text), 1)\n        if special_ratio &gt; 0.3:\n            return True, \"Excessive special characters\"\n\n        return False, \"\"\n</code></pre></p> <p>Anomaly Detection (<code>monitoring.py:215</code>) <pre><code>class AnomalyDetector:\n    \"\"\"Detect anomalous user behavior\"\"\"\n\n    def detect(self, user_id: str, message: str, hour: int) -&gt; List[str]:\n        \"\"\"Detect anomalies in user behavior\"\"\"\n        anomalies = []\n\n        # Very long messages\n        if len(message) &gt; 1000:\n            anomalies.append('unusually_long_message')\n\n        # Off-hours usage (outside 8am-11pm)\n        if hour &lt; 8 or hour &gt; 23:\n            anomalies.append('off_hours_usage')\n\n        return anomalies\n</code></pre></p> <p>Controls: - Prompt injection detection - Command injection detection - Anomalous message length detection - Off-hours usage detection</p>"},{"location":"security/overview/#layer-5-secrets-management","title":"Layer 5: Secrets Management","text":"<p>Environment Variables (<code>security.py:245</code>) <pre><code>class SecretsManager:\n    \"\"\"Manage secrets from environment or Docker secrets\"\"\"\n\n    @staticmethod\n    def get_secret(name: str, required: bool = True) -&gt; Optional[str]:\n        \"\"\"Get secret from Docker secrets or environment\"\"\"\n\n        # Check Docker secrets first\n        secret_file = f\"/run/secrets/{name.lower()}\"\n        if os.path.exists(secret_file):\n            with open(secret_file) as f:\n                return f.read().strip()\n\n        # Fallback to environment variable\n        value = os.environ.get(name)\n\n        if required and not value:\n            raise ValueError(f\"Required secret {name} not set\")\n\n        return value\n\n    @staticmethod\n    def validate_api_key(key: str) -&gt; bool:\n        \"\"\"Validate OpenAI API key format\"\"\"\n        return key.startswith(\"sk-\") and len(key) &gt; 20\n\n    @staticmethod\n    def validate_phone_number(number: str) -&gt; bool:\n        \"\"\"Validate E.164 phone number format\"\"\"\n        import re\n        return bool(re.match(r'^\\+[1-9]\\d{7,14}$', number))\n</code></pre></p> <p>Controls: - Docker secrets support - Environment variable fallback - API key format validation - Phone number format validation (E.164) - No credential logging</p>"},{"location":"security/overview/#security-controls-summary","title":"Security Controls Summary","text":""},{"location":"security/overview/#preventive-controls","title":"Preventive Controls","text":"Control Implementation Status Input Validation <code>security.py:78</code> \u2705 Active Rate Limiting <code>security.py:112</code> \u2705 Active Passphrase Activation <code>security.py:15</code> \u2705 Active Prompt Hardening <code>custom_rag.py:156</code> \u2705 Active Secrets Management <code>security.py:245</code> \u2705 Active"},{"location":"security/overview/#detective-controls","title":"Detective Controls","text":"Control Implementation Status Threat Detection <code>security.py:187</code> \u2705 Active Anomaly Detection <code>monitoring.py:215</code> \u2705 Active Audit Logging <code>monitoring.py:45</code> \u2705 Active Security Metrics <code>monitoring.py:178</code> \u2705 Active"},{"location":"security/overview/#responsive-controls","title":"Responsive Controls","text":"Control Implementation Status Circuit Breaker <code>error_handling.py:89</code> \u2705 Active Auto-Remediation <code>error_handling.py:145</code> \u2705 Active Alert System <code>monitoring.py:289</code> \u2705 Active"},{"location":"security/overview/#common-threats-mitigations","title":"Common Threats &amp; Mitigations","text":""},{"location":"security/overview/#threat-01-passphrase-brute-force","title":"THREAT-01: Passphrase Brute Force","text":"<p>Attack: Automated guessing of activation passphrase</p> <p>Impact: Unauthorized access to RAG</p> <p>Mitigation: - Rate limiting (10 attempts/minute) - Account lockout after 100 failed attempts/hour - Audit logging of failed activations - Strong passphrase requirement (configurable)</p> <p>Detection: Monitor for repeated activation failures from same user</p>"},{"location":"security/overview/#threat-02-api-key-theft","title":"THREAT-02: API Key Theft","text":"<p>Attack: Environment variable exposure, memory dump, logs</p> <p>Impact: Financial loss, quota exhaustion</p> <p>Mitigation: - Secrets via Docker secrets or <code>.env</code> (not in code) - API key redaction in all logs and error messages - Key format validation on startup - Support for key rotation without code changes</p> <p>Detection: Monitor for unusual API usage patterns, quota warnings</p>"},{"location":"security/overview/#threat-03-prompt-injection","title":"THREAT-03: Prompt Injection","text":"<p>Attack: Crafted queries to manipulate RAG responses</p> <p>Impact: Misinformation, data extraction, system prompt exposure</p> <p>Mitigation: - Input sanitization (remove injection patterns) - Prompt hardening (clear boundaries, instruction isolation) - Output filtering (validate response format) - Context isolation (RAG context clearly separated)</p> <p>Detection: Suspicious pattern detection, anomaly alerts</p>"},{"location":"security/overview/#threat-04-denial-of-service","title":"THREAT-04: Denial of Service","text":"<p>Attack: Message flooding, resource exhaustion</p> <p>Impact: Service unavailability, cost spike</p> <p>Mitigation: - Rate limiting (10 msg/min, 100 msg/hour) - Resource limits (2GB RAM, 2 CPU cores) - Circuit breaker on OpenAI API failures - Health checks and auto-restart</p> <p>Detection: High message rate alerts, resource usage monitoring</p>"},{"location":"security/overview/#threat-05-data-exfiltration","title":"THREAT-05: Data Exfiltration","text":"<p>Attack: Iterative querying to extract full knowledge base</p> <p>Impact: IP theft, competitive intelligence loss</p> <p>Mitigation: - Rate limiting on queries - Response size limits (200 tokens default) - Query pattern detection (repeated similar queries) - Audit logging of all queries</p> <p>Detection: Anomaly detection for unusual query patterns</p>"},{"location":"security/overview/#security-testing","title":"Security Testing","text":""},{"location":"security/overview/#automated-tests","title":"Automated Tests","text":"<p>Run security test suite: <pre><code>pytest tests/test_security.py -v\n</code></pre></p> <p>Test Coverage: - Input validation (31 tests) - Rate limiting enforcement (8 tests) - Threat detection (12 tests) - Secrets management (6 tests)</p>"},{"location":"security/overview/#manual-security-audit","title":"Manual Security Audit","text":"<pre><code># Run security audit script\n./scripts/security_audit.sh\n</code></pre> <p>Checks: - Hardcoded secrets in code - <code>.env</code> in <code>.gitignore</code> - File permissions - Dependency vulnerabilities (via <code>safety</code>) - Debug mode disabled</p>"},{"location":"security/overview/#penetration-testing","title":"Penetration Testing","text":"<p>Recommended scenarios: 1. Passphrase Brute Force: Attempt 1000 activation attempts 2. Prompt Injection: Try to extract system prompt or manipulate responses 3. Rate Limit Bypass: Use multiple accounts or timing attacks 4. Input Validation: Test with special characters, very long messages 5. API Key Extraction: Look for leaks in logs, errors, responses</p>"},{"location":"security/overview/#incident-response","title":"Incident Response","text":""},{"location":"security/overview/#severity-levels","title":"Severity Levels","text":"Level Description Response Time P0 Critical (API key leaked, account takeover) &lt; 15 min P1 High (service outage, security vuln) &lt; 1 hour P2 Medium (degraded performance, suspicious activity) &lt; 4 hours P3 Low (minor issues) &lt; 24 hours"},{"location":"security/overview/#response-procedures","title":"Response Procedures","text":"<p>See detailed procedures in Incident Response Runbook</p> <p>Quick Actions:</p> <p>API Key Compromise: <pre><code># 1. Revoke old key in OpenAI dashboard\n# 2. Generate new key\n# 3. Update .env\nexport OPENAI_API_KEY=\"new_key_here\"\n# 4. Restart bot\ndocker-compose restart\n</code></pre></p> <p>Signal Account Takeover: <pre><code># 1. Unlink all devices in Signal app\n# 2. Stop bot\ndocker-compose down\n# 3. Remove signal-cli data\ndocker volume rm signal-data\n# 4. Re-link and restart\ndocker-compose up -d\n</code></pre></p>"},{"location":"security/overview/#security-best-practices","title":"Security Best Practices","text":""},{"location":"security/overview/#pre-deployment","title":"Pre-Deployment","text":"<ul> <li> Use strong, unique activation passphrase</li> <li> Configure user whitelist if limiting access</li> <li> Use Docker secrets (not environment variables) in production</li> <li> Review audit logs for testing artifacts</li> <li> Run security test suite</li> <li> Scan dependencies for vulnerabilities</li> <li> Enable monitoring and alerting</li> </ul>"},{"location":"security/overview/#post-deployment","title":"Post-Deployment","text":"<ul> <li> Monitor failed activation attempts</li> <li> Review audit logs weekly</li> <li> Check for unusual API usage patterns</li> <li> Update dependencies monthly</li> <li> Rotate API keys quarterly</li> <li> Conduct security review quarterly</li> <li> Test backup/restore procedures</li> </ul>"},{"location":"security/overview/#ongoing-operations","title":"Ongoing Operations","text":"<ul> <li> Monitor security alerts in real-time</li> <li> Investigate anomalies within 24 hours</li> <li> Update dependencies within 7 days of security patches</li> <li> Conduct penetration testing annually</li> <li> Review and update threat model quarterly</li> </ul>"},{"location":"security/overview/#compliance","title":"Compliance","text":""},{"location":"security/overview/#gdpr-considerations","title":"GDPR Considerations","text":"<p>Personal Data Processing: - Phone numbers (hashed in logs) - Message timestamps - No message content retention</p> <p>Legal Basis: Legitimate interest (service operation)</p> <p>User Rights: - Right to be forgotten (automatic on restart) - Data minimization (in-memory only) - No third-party sharing (except OpenAI for processing)</p>"},{"location":"security/overview/#security-standards-alignment","title":"Security Standards Alignment","text":"<ul> <li>\u2705 OWASP Top 10: Mitigations for injection, broken auth, sensitive data exposure</li> <li>\u2705 CIS Controls: Input validation, secure configuration, audit logging</li> <li>\u2705 NIST CSF: Identify, Protect, Detect, Respond, Recover</li> </ul>"},{"location":"security/overview/#next-steps","title":"Next Steps","text":"<ul> <li>\ud83d\udcd6 Input Validation - Detailed sanitization guide</li> <li>\ud83d\udea6 Rate Limiting - Rate limiter configuration</li> <li>\ud83d\udd0d Threat Detection - Suspicious pattern detection</li> <li>\u2705 Security Best Practices - Comprehensive security checklist</li> </ul>"},{"location":"security/overview/#reference","title":"Reference","text":"<ul> <li>Security Module Source</li> <li>Security Test Suite</li> <li>SECURITY.md</li> </ul>"}]}